{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.metrics         import confusion_matrix\n",
    "from keras.models            import Sequential\n",
    "from keras.layers            import Input\n",
    "from keras.layers            import Dense\n",
    "from keras.layers            import BatchNormalization\n",
    "from keras.layers            import Activation\n",
    "from keras.layers            import Dropout\n",
    "from keras.optimizers        import Adam\n",
    "from keras.utils.np_utils    import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm                    import tqdm\n",
    "from collections             import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_std_df = pd.read_csv(data_path + 'creditcard.csv')\n",
    "non_std_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.157366e-16</td>\n",
       "      <td>3.154853e-17</td>\n",
       "      <td>-4.409878e-15</td>\n",
       "      <td>-6.734811e-16</td>\n",
       "      <td>-2.874435e-16</td>\n",
       "      <td>4.168992e-16</td>\n",
       "      <td>-8.767997e-16</td>\n",
       "      <td>-2.423604e-16</td>\n",
       "      <td>3.078727e-16</td>\n",
       "      <td>2.026926e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.754870e-16</td>\n",
       "      <td>1.685077e-17</td>\n",
       "      <td>1.478472e-15</td>\n",
       "      <td>-6.797197e-16</td>\n",
       "      <td>1.234659e-16</td>\n",
       "      <td>-7.659279e-16</td>\n",
       "      <td>3.247603e-16</td>\n",
       "      <td>-2.953495e-18</td>\n",
       "      <td>5.401572e-17</td>\n",
       "      <td>3.202236e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.879855e+01</td>\n",
       "      <td>-4.403529e+01</td>\n",
       "      <td>-3.187173e+01</td>\n",
       "      <td>-4.013919e+00</td>\n",
       "      <td>-8.240810e+01</td>\n",
       "      <td>-1.963606e+01</td>\n",
       "      <td>-3.520940e+01</td>\n",
       "      <td>-6.130252e+01</td>\n",
       "      <td>-1.222802e+01</td>\n",
       "      <td>-2.258191e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.069146e+01</td>\n",
       "      <td>-4.741907e+01</td>\n",
       "      <td>-1.506565e+01</td>\n",
       "      <td>-7.175446e+01</td>\n",
       "      <td>-4.683638e+00</td>\n",
       "      <td>-1.975033e+01</td>\n",
       "      <td>-5.401098e+00</td>\n",
       "      <td>-5.590660e+01</td>\n",
       "      <td>-4.674612e+01</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.698918e-01</td>\n",
       "      <td>-3.624707e-01</td>\n",
       "      <td>-5.872142e-01</td>\n",
       "      <td>-5.993788e-01</td>\n",
       "      <td>-5.010686e-01</td>\n",
       "      <td>-5.766822e-01</td>\n",
       "      <td>-4.478860e-01</td>\n",
       "      <td>-1.746805e-01</td>\n",
       "      <td>-5.853631e-01</td>\n",
       "      <td>-4.917360e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.746334e-01</td>\n",
       "      <td>-3.109433e-01</td>\n",
       "      <td>-7.473476e-01</td>\n",
       "      <td>-2.591784e-01</td>\n",
       "      <td>-5.854676e-01</td>\n",
       "      <td>-6.084001e-01</td>\n",
       "      <td>-6.780717e-01</td>\n",
       "      <td>-1.755053e-01</td>\n",
       "      <td>-1.604440e-01</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.245351e-03</td>\n",
       "      <td>3.965683e-02</td>\n",
       "      <td>1.186124e-01</td>\n",
       "      <td>-1.401724e-02</td>\n",
       "      <td>-3.936682e-02</td>\n",
       "      <td>-2.058046e-01</td>\n",
       "      <td>3.241723e-02</td>\n",
       "      <td>1.871982e-02</td>\n",
       "      <td>-4.681169e-02</td>\n",
       "      <td>-8.533551e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.104705e-02</td>\n",
       "      <td>-4.009429e-02</td>\n",
       "      <td>9.345377e-03</td>\n",
       "      <td>-1.792420e-02</td>\n",
       "      <td>6.765678e-02</td>\n",
       "      <td>3.183240e-02</td>\n",
       "      <td>-1.081217e-01</td>\n",
       "      <td>3.325174e-03</td>\n",
       "      <td>3.406368e-02</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.716939e-01</td>\n",
       "      <td>4.867202e-01</td>\n",
       "      <td>6.774569e-01</td>\n",
       "      <td>5.250082e-01</td>\n",
       "      <td>4.433465e-01</td>\n",
       "      <td>2.991625e-01</td>\n",
       "      <td>4.611107e-01</td>\n",
       "      <td>2.740785e-01</td>\n",
       "      <td>5.435305e-01</td>\n",
       "      <td>4.168842e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.725733e-01</td>\n",
       "      <td>2.537392e-01</td>\n",
       "      <td>7.283360e-01</td>\n",
       "      <td>2.364319e-01</td>\n",
       "      <td>7.257153e-01</td>\n",
       "      <td>6.728006e-01</td>\n",
       "      <td>4.996663e-01</td>\n",
       "      <td>2.255648e-01</td>\n",
       "      <td>2.371526e-01</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.253351e+00</td>\n",
       "      <td>1.335775e+01</td>\n",
       "      <td>6.187993e+00</td>\n",
       "      <td>1.191874e+01</td>\n",
       "      <td>2.521413e+01</td>\n",
       "      <td>5.502015e+01</td>\n",
       "      <td>9.747824e+01</td>\n",
       "      <td>1.675153e+01</td>\n",
       "      <td>1.419494e+01</td>\n",
       "      <td>2.180758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.113464e+01</td>\n",
       "      <td>3.703471e+01</td>\n",
       "      <td>1.447304e+01</td>\n",
       "      <td>3.607668e+01</td>\n",
       "      <td>7.569684e+00</td>\n",
       "      <td>1.442532e+01</td>\n",
       "      <td>7.293975e+00</td>\n",
       "      <td>7.831940e+01</td>\n",
       "      <td>1.025434e+02</td>\n",
       "      <td>1.023622e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -8.157366e-16  3.154853e-17 -4.409878e-15 -6.734811e-16 -2.874435e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -2.879855e+01 -4.403529e+01 -3.187173e+01 -4.013919e+00 -8.240810e+01   \n",
       "25%   -4.698918e-01 -3.624707e-01 -5.872142e-01 -5.993788e-01 -5.010686e-01   \n",
       "50%    9.245351e-03  3.965683e-02  1.186124e-01 -1.401724e-02 -3.936682e-02   \n",
       "75%    6.716939e-01  4.867202e-01  6.774569e-01  5.250082e-01  4.433465e-01   \n",
       "max    1.253351e+00  1.335775e+01  6.187993e+00  1.191874e+01  2.521413e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.168992e-16 -8.767997e-16 -2.423604e-16  3.078727e-16  2.026926e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -1.963606e+01 -3.520940e+01 -6.130252e+01 -1.222802e+01 -2.258191e+01   \n",
       "25%   -5.766822e-01 -4.478860e-01 -1.746805e-01 -5.853631e-01 -4.917360e-01   \n",
       "50%   -2.058046e-01  3.241723e-02  1.871982e-02 -4.681169e-02 -8.533551e-02   \n",
       "75%    2.991625e-01  4.611107e-01  2.740785e-01  5.435305e-01  4.168842e-01   \n",
       "max    5.502015e+01  9.747824e+01  1.675153e+01  1.419494e+01  2.180758e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...       2.754870e-16  1.685077e-17  1.478472e-15 -6.797197e-16   \n",
       "std        ...       1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min        ...      -7.069146e+01 -4.741907e+01 -1.506565e+01 -7.175446e+01   \n",
       "25%        ...      -2.746334e-01 -3.109433e-01 -7.473476e-01 -2.591784e-01   \n",
       "50%        ...      -8.104705e-02 -4.009429e-02  9.345377e-03 -1.792420e-02   \n",
       "75%        ...       1.725733e-01  2.537392e-01  7.283360e-01  2.364319e-01   \n",
       "max        ...       5.113464e+01  3.703471e+01  1.447304e+01  3.607668e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.234659e-16 -7.659279e-16  3.247603e-16 -2.953495e-18  5.401572e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -4.683638e+00 -1.975033e+01 -5.401098e+00 -5.590660e+01 -4.674612e+01   \n",
       "25%   -5.854676e-01 -6.084001e-01 -6.780717e-01 -1.755053e-01 -1.604440e-01   \n",
       "50%    6.765678e-02  3.183240e-02 -1.081217e-01  3.325174e-03  3.406368e-02   \n",
       "75%    7.257153e-01  6.728006e-01  4.996663e-01  2.255648e-01  2.371526e-01   \n",
       "max    7.569684e+00  1.442532e+01  7.293975e+00  7.831940e+01  1.025434e+02   \n",
       "\n",
       "             Amount  \n",
       "count  2.848070e+05  \n",
       "mean   3.202236e-16  \n",
       "std    1.000002e+00  \n",
       "min   -3.532294e-01  \n",
       "25%   -3.308401e-01  \n",
       "50%   -2.652715e-01  \n",
       "75%   -4.471707e-02  \n",
       "max    1.023622e+02  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features    = non_std_df.drop(['Class', 'Time'], axis = 1)\n",
    "target      = non_std_df['Class']\n",
    "scaler      = StandardScaler()\n",
    "features[:] = scaler.fit_transform(features)\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 492)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(non_std_df['Class'] == 0).sum(), (non_std_df['Class'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_file = open(data_path + 'scaler.pkl', 'wb')\n",
    "pickle.dump(scaler, scaler_file)\n",
    "scaler_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([features, target], axis = 1)\n",
    "df.to_csv(data_path + 'standardized_credit_card.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_file = open(data_path + 'scaler.pkl', 'rb')\n",
    "scaler      = pickle.load(scaler_file)\n",
    "df          = pd.read_csv(data_path + 'standardized_credit_card.csv')\n",
    "scaler_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.155493e-16</td>\n",
       "      <td>3.228412e-17</td>\n",
       "      <td>-4.365170e-15</td>\n",
       "      <td>-6.671495e-16</td>\n",
       "      <td>-2.363387e-16</td>\n",
       "      <td>4.264686e-16</td>\n",
       "      <td>-8.693495e-16</td>\n",
       "      <td>-2.340305e-16</td>\n",
       "      <td>2.994106e-16</td>\n",
       "      <td>2.085242e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391983e-18</td>\n",
       "      <td>1.458816e-15</td>\n",
       "      <td>-6.835906e-16</td>\n",
       "      <td>1.216423e-16</td>\n",
       "      <td>-7.920876e-16</td>\n",
       "      <td>3.210547e-16</td>\n",
       "      <td>1.534291e-20</td>\n",
       "      <td>5.322985e-17</td>\n",
       "      <td>3.187345e-16</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.879855e+01</td>\n",
       "      <td>-4.403529e+01</td>\n",
       "      <td>-3.187173e+01</td>\n",
       "      <td>-4.013919e+00</td>\n",
       "      <td>-8.240810e+01</td>\n",
       "      <td>-1.963606e+01</td>\n",
       "      <td>-3.520940e+01</td>\n",
       "      <td>-6.130252e+01</td>\n",
       "      <td>-1.222802e+01</td>\n",
       "      <td>-2.258191e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.741907e+01</td>\n",
       "      <td>-1.506565e+01</td>\n",
       "      <td>-7.175446e+01</td>\n",
       "      <td>-4.683638e+00</td>\n",
       "      <td>-1.975033e+01</td>\n",
       "      <td>-5.401098e+00</td>\n",
       "      <td>-5.590660e+01</td>\n",
       "      <td>-4.674612e+01</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.698918e-01</td>\n",
       "      <td>-3.624707e-01</td>\n",
       "      <td>-5.872142e-01</td>\n",
       "      <td>-5.993788e-01</td>\n",
       "      <td>-5.010686e-01</td>\n",
       "      <td>-5.766822e-01</td>\n",
       "      <td>-4.478860e-01</td>\n",
       "      <td>-1.746805e-01</td>\n",
       "      <td>-5.853631e-01</td>\n",
       "      <td>-4.917360e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.109433e-01</td>\n",
       "      <td>-7.473476e-01</td>\n",
       "      <td>-2.591784e-01</td>\n",
       "      <td>-5.854676e-01</td>\n",
       "      <td>-6.084001e-01</td>\n",
       "      <td>-6.780717e-01</td>\n",
       "      <td>-1.755053e-01</td>\n",
       "      <td>-1.604440e-01</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.245351e-03</td>\n",
       "      <td>3.965683e-02</td>\n",
       "      <td>1.186124e-01</td>\n",
       "      <td>-1.401724e-02</td>\n",
       "      <td>-3.936682e-02</td>\n",
       "      <td>-2.058046e-01</td>\n",
       "      <td>3.241723e-02</td>\n",
       "      <td>1.871982e-02</td>\n",
       "      <td>-4.681169e-02</td>\n",
       "      <td>-8.533551e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.009429e-02</td>\n",
       "      <td>9.345377e-03</td>\n",
       "      <td>-1.792420e-02</td>\n",
       "      <td>6.765678e-02</td>\n",
       "      <td>3.183240e-02</td>\n",
       "      <td>-1.081217e-01</td>\n",
       "      <td>3.325174e-03</td>\n",
       "      <td>3.406368e-02</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.716939e-01</td>\n",
       "      <td>4.867202e-01</td>\n",
       "      <td>6.774569e-01</td>\n",
       "      <td>5.250082e-01</td>\n",
       "      <td>4.433465e-01</td>\n",
       "      <td>2.991625e-01</td>\n",
       "      <td>4.611107e-01</td>\n",
       "      <td>2.740785e-01</td>\n",
       "      <td>5.435305e-01</td>\n",
       "      <td>4.168842e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.537392e-01</td>\n",
       "      <td>7.283360e-01</td>\n",
       "      <td>2.364319e-01</td>\n",
       "      <td>7.257153e-01</td>\n",
       "      <td>6.728006e-01</td>\n",
       "      <td>4.996663e-01</td>\n",
       "      <td>2.255648e-01</td>\n",
       "      <td>2.371526e-01</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.253351e+00</td>\n",
       "      <td>1.335775e+01</td>\n",
       "      <td>6.187993e+00</td>\n",
       "      <td>1.191874e+01</td>\n",
       "      <td>2.521413e+01</td>\n",
       "      <td>5.502015e+01</td>\n",
       "      <td>9.747824e+01</td>\n",
       "      <td>1.675153e+01</td>\n",
       "      <td>1.419494e+01</td>\n",
       "      <td>2.180758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.703471e+01</td>\n",
       "      <td>1.447304e+01</td>\n",
       "      <td>3.607668e+01</td>\n",
       "      <td>7.569684e+00</td>\n",
       "      <td>1.442532e+01</td>\n",
       "      <td>7.293975e+00</td>\n",
       "      <td>7.831940e+01</td>\n",
       "      <td>1.025434e+02</td>\n",
       "      <td>1.023622e+02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -8.155493e-16  3.228412e-17 -4.365170e-15 -6.671495e-16 -2.363387e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -2.879855e+01 -4.403529e+01 -3.187173e+01 -4.013919e+00 -8.240810e+01   \n",
       "25%   -4.698918e-01 -3.624707e-01 -5.872142e-01 -5.993788e-01 -5.010686e-01   \n",
       "50%    9.245351e-03  3.965683e-02  1.186124e-01 -1.401724e-02 -3.936682e-02   \n",
       "75%    6.716939e-01  4.867202e-01  6.774569e-01  5.250082e-01  4.433465e-01   \n",
       "max    1.253351e+00  1.335775e+01  6.187993e+00  1.191874e+01  2.521413e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.264686e-16 -8.693495e-16 -2.340305e-16  2.994106e-16  2.085242e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -1.963606e+01 -3.520940e+01 -6.130252e+01 -1.222802e+01 -2.258191e+01   \n",
       "25%   -5.766822e-01 -4.478860e-01 -1.746805e-01 -5.853631e-01 -4.917360e-01   \n",
       "50%   -2.058046e-01  3.241723e-02  1.871982e-02 -4.681169e-02 -8.533551e-02   \n",
       "75%    2.991625e-01  4.611107e-01  2.740785e-01  5.435305e-01  4.168842e-01   \n",
       "max    5.502015e+01  9.747824e+01  1.675153e+01  1.419494e+01  2.180758e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        3.391983e-18  1.458816e-15 -6.835906e-16  1.216423e-16   \n",
       "std        ...        1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min        ...       -4.741907e+01 -1.506565e+01 -7.175446e+01 -4.683638e+00   \n",
       "25%        ...       -3.109433e-01 -7.473476e-01 -2.591784e-01 -5.854676e-01   \n",
       "50%        ...       -4.009429e-02  9.345377e-03 -1.792420e-02  6.765678e-02   \n",
       "75%        ...        2.537392e-01  7.283360e-01  2.364319e-01  7.257153e-01   \n",
       "max        ...        3.703471e+01  1.447304e+01  3.607668e+01  7.569684e+00   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -7.920876e-16  3.210547e-16  1.534291e-20  5.322985e-17  3.187345e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -1.975033e+01 -5.401098e+00 -5.590660e+01 -4.674612e+01 -3.532294e-01   \n",
       "25%   -6.084001e-01 -6.780717e-01 -1.755053e-01 -1.604440e-01 -3.308401e-01   \n",
       "50%    3.183240e-02 -1.081217e-01  3.325174e-03  3.406368e-02 -2.652715e-01   \n",
       "75%    6.728006e-01  4.996663e-01  2.255648e-01  2.371526e-01 -4.471707e-02   \n",
       "max    1.442532e+01  7.293975e+00  7.831940e+01  1.025434e+02  1.023622e+02   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_batch(big_class, small_class, final_proportion):\n",
    "    batch_size              = int(round(big_class.shape[0] / (1 - final_proportion)))\n",
    "    print('batch size', batch_size)\n",
    "    small_class_sample_size = int(round(batch_size * final_proportion))  \n",
    "    print('small_class_sample_size', small_class_sample_size)\n",
    "    oversampled_small       = small_class.sample(small_class_sample_size, replace = True)\n",
    "    \n",
    "    return pd.concat([big_class, oversampled_small])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_to_numpy_arrays(df, test_prop):\n",
    "    # regular transaction df\n",
    "    reg_df   = df[df['Class'] == 0]\n",
    "    reg_feat = reg_df.drop(['Class'], axis = 1)\n",
    "    reg_targ = reg_df['Class']\n",
    "\n",
    "    # anomalies transaction df\n",
    "    anom_df   = df[df['Class'] == 1]\n",
    "    anom_feat = anom_df.drop(['Class'], axis = 1)\n",
    "    anom_targ = anom_df['Class']\n",
    "\n",
    "    # splitting\n",
    "    reg_feat_train, reg_feat_test, reg_targ_train, reg_targ_test     = train_test_split(reg_feat, reg_targ, test_size = test_prop)\n",
    "    anom_feat_train, anom_feat_test, anom_targ_train, anom_targ_test = train_test_split(anom_feat, anom_targ, test_size = test_prop)\n",
    "    \n",
    "    train_feat   = pd.concat([reg_feat_train, anom_feat_train]).as_matrix()\n",
    "    train_target = to_categorical(pd.concat([reg_targ_train, anom_targ_train]).as_matrix())\n",
    "    test_feat    = pd.concat([reg_feat_test, anom_feat_test]).as_matrix()\n",
    "    test_target  = to_categorical(pd.concat([reg_targ_test, anom_targ_test]).as_matrix())\n",
    "\n",
    "    return train_feat, train_target, test_feat, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, df, steps, epoch_start, epoch_end, fit_params, validation_prop):\n",
    "    small_class_prop = df[df['Class'] == 1].shape[0] / df.shape[0]\n",
    "    step_values      = np.linspace(0.5, small_class_prop, steps)\n",
    "    epochs           = np.linspace(epoch_start, epoch_end, steps)\n",
    "    big_class        = df[df['Class'] == 0]\n",
    "    small_class      = df[df['Class'] == 1]\n",
    "    \n",
    "    for step, epoch in tqdm(zip(step_values, epochs)):\n",
    "        training_batch                   = generate_training_batch(big_class, small_class, step)\n",
    "        X_train, y_train, X_test, y_test = df_to_numpy_arrays(training_batch, validation_prop)\n",
    "        fit_params['x']                  = X_train\n",
    "        fit_params['y']                  = y_train\n",
    "        fit_params['epochs']             = int(round(epoch))\n",
    "        fit_params['validation_data']    = (X_test, y_test)\n",
    "        print('Oversampling small class to %.4f%% of the training data, %d epochs' % (100 * step, fit_params['epochs']))\n",
    "        model.fit(**fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(256, input_shape = (30,)),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dropout(0.50),\n",
    "#     Dense(256),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dropout(0.6),\n",
    "#     Dense(256),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dropout(0.7),\n",
    "#     Dense(2, activation = 'softmax')\n",
    "# ])\n",
    "# model.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, input_shape = (30,)),\n",
    "    Activation('relu'),\n",
    "    Dense(256),\n",
    "    Activation('relu'),\n",
    "    Dense(2, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer = Adam(1e-7), loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'batch_size': 2048,\n",
    "    'verbose'   : 2\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'model'          : model,\n",
    "    'df'             : df,\n",
    "    'steps'          : 15,\n",
    "    'epoch_start'    : 8,\n",
    "    'epoch_end'      : 8,\n",
    "    'fit_params'     : fit_params,\n",
    "    'validation_prop': 0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 568630\n",
      "small_class_sample_size 284315\n",
      "Oversampling small class to 50.0000% of the training data, 8 epochs\n",
      "Train on 483334 samples, validate on 85296 samples\n",
      "Epoch 1/8\n",
      "2s - loss: 3.0886 - val_loss: 0.5368\n",
      "Epoch 2/8\n",
      "1s - loss: 0.5087 - val_loss: 0.5420\n",
      "Epoch 3/8\n",
      "2s - loss: 0.5069 - val_loss: 0.5095\n",
      "Epoch 4/8\n",
      "2s - loss: 0.5043 - val_loss: 0.6866\n",
      "Epoch 5/8\n",
      "1s - loss: 0.5067 - val_loss: 0.5092\n",
      "Epoch 6/8\n",
      "2s - loss: 0.4987 - val_loss: 0.5193\n",
      "Epoch 7/8\n",
      "2s - loss: 0.4987 - val_loss: 0.4964\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:17, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.4956 - val_loss: 0.7180\n",
      "batch size 530844\n",
      "small_class_sample_size 246529\n",
      "Oversampling small class to 46.4409% of the training data, 8 epochs\n",
      "Train on 451216 samples, validate on 79628 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.5015 - val_loss: 0.4881\n",
      "Epoch 2/8\n",
      "1s - loss: 0.4906 - val_loss: 0.4881\n",
      "Epoch 3/8\n",
      "1s - loss: 0.4884 - val_loss: 0.4850\n",
      "Epoch 4/8\n",
      "1s - loss: 0.4883 - val_loss: 0.4845\n",
      "Epoch 5/8\n",
      "2s - loss: 0.4857 - val_loss: 0.4890\n",
      "Epoch 6/8\n",
      "2s - loss: 0.4842 - val_loss: 0.4874\n",
      "Epoch 7/8\n",
      "1s - loss: 0.4811 - val_loss: 0.4778\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:32, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2s - loss: 0.4800 - val_loss: 0.4754\n",
      "batch size 497766\n",
      "small_class_sample_size 213451\n",
      "Oversampling small class to 42.8818% of the training data, 8 epochs\n",
      "Train on 423100 samples, validate on 74666 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.4731 - val_loss: 0.4723\n",
      "Epoch 2/8\n",
      "1s - loss: 0.4706 - val_loss: 0.4787\n",
      "Epoch 3/8\n",
      "1s - loss: 0.4709 - val_loss: 0.4694\n",
      "Epoch 4/8\n",
      "1s - loss: 0.4682 - val_loss: 0.4735\n",
      "Epoch 5/8\n",
      "1s - loss: 0.4670 - val_loss: 0.4678\n",
      "Epoch 6/8\n",
      "1s - loss: 0.4661 - val_loss: 0.4646\n",
      "Epoch 7/8\n",
      "1s - loss: 0.4643 - val_loss: 0.4628\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:47, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.4618 - val_loss: 0.4646\n",
      "batch size 468569\n",
      "small_class_sample_size 184254\n",
      "Oversampling small class to 39.3227% of the training data, 8 epochs\n",
      "Train on 398282 samples, validate on 70287 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.4556 - val_loss: 0.4539\n",
      "Epoch 2/8\n",
      "1s - loss: 0.4537 - val_loss: 0.4510\n",
      "Epoch 3/8\n",
      "1s - loss: 0.4531 - val_loss: 0.4524\n",
      "Epoch 4/8\n",
      "1s - loss: 0.4520 - val_loss: 0.4526\n",
      "Epoch 5/8\n",
      "1s - loss: 0.4513 - val_loss: 0.4474\n",
      "Epoch 6/8\n",
      "1s - loss: 0.4501 - val_loss: 0.4458\n",
      "Epoch 7/8\n",
      "1s - loss: 0.4480 - val_loss: 0.4517\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:01, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.4469 - val_loss: 0.4448\n",
      "batch size 442608\n",
      "small_class_sample_size 158293\n",
      "Oversampling small class to 35.7636% of the training data, 8 epochs\n",
      "Train on 376216 samples, validate on 66392 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.4377 - val_loss: 0.4320\n",
      "Epoch 2/8\n",
      "1s - loss: 0.4371 - val_loss: 0.4297\n",
      "Epoch 3/8\n",
      "1s - loss: 0.4368 - val_loss: 0.4287\n",
      "Epoch 4/8\n",
      "1s - loss: 0.4340 - val_loss: 0.4322\n",
      "Epoch 5/8\n",
      "1s - loss: 0.4331 - val_loss: 0.4289\n",
      "Epoch 6/8\n",
      "1s - loss: 0.4333 - val_loss: 0.4261\n",
      "Epoch 7/8\n",
      "1s - loss: 0.4310 - val_loss: 0.4242\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:13, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.4298 - val_loss: 0.4232\n",
      "batch size 419372\n",
      "small_class_sample_size 135057\n",
      "Oversampling small class to 32.2046% of the training data, 8 epochs\n",
      "Train on 356465 samples, validate on 62907 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.4188 - val_loss: 0.4198\n",
      "Epoch 2/8\n",
      "1s - loss: 0.4176 - val_loss: 0.4753\n",
      "Epoch 3/8\n",
      "1s - loss: 0.4207 - val_loss: 0.4159\n",
      "Epoch 4/8\n",
      "1s - loss: 0.4154 - val_loss: 0.4170\n",
      "Epoch 5/8\n",
      "1s - loss: 0.4158 - val_loss: 0.4212\n",
      "Epoch 6/8\n",
      "1s - loss: 0.4155 - val_loss: 0.4130\n",
      "Epoch 7/8\n",
      "1s - loss: 0.4135 - val_loss: 0.4194\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:25, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.4133 - val_loss: 0.4140\n",
      "batch size 398454\n",
      "small_class_sample_size 114139\n",
      "Oversampling small class to 28.6455% of the training data, 8 epochs\n",
      "Train on 338685 samples, validate on 59769 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.4002 - val_loss: 0.3970\n",
      "Epoch 2/8\n",
      "1s - loss: 0.3992 - val_loss: 0.4023\n",
      "Epoch 3/8\n",
      "1s - loss: 0.3975 - val_loss: 0.4048\n",
      "Epoch 4/8\n",
      "1s - loss: 0.3985 - val_loss: 0.3952\n",
      "Epoch 5/8\n",
      "1s - loss: 0.3978 - val_loss: 0.4012\n",
      "Epoch 6/8\n",
      "1s - loss: 0.3971 - val_loss: 0.3965\n",
      "Epoch 7/8\n",
      "1s - loss: 0.3948 - val_loss: 0.3918\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [01:37, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.3954 - val_loss: 0.3925\n",
      "batch size 379524\n",
      "small_class_sample_size 95209\n",
      "Oversampling small class to 25.0864% of the training data, 8 epochs\n",
      "Train on 322594 samples, validate on 56930 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.3792 - val_loss: 0.3755\n",
      "Epoch 2/8\n",
      "1s - loss: 0.3774 - val_loss: 0.3751\n",
      "Epoch 3/8\n",
      "1s - loss: 0.3792 - val_loss: 0.3747\n",
      "Epoch 4/8\n",
      "1s - loss: 0.3760 - val_loss: 0.3754\n",
      "Epoch 5/8\n",
      "1s - loss: 0.3765 - val_loss: 0.3734\n",
      "Epoch 6/8\n",
      "1s - loss: 0.3758 - val_loss: 0.3753\n",
      "Epoch 7/8\n",
      "1s - loss: 0.3750 - val_loss: 0.3716\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [01:47, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.3737 - val_loss: 0.3771\n",
      "batch size 362311\n",
      "small_class_sample_size 77996\n",
      "Oversampling small class to 21.5273% of the training data, 8 epochs\n",
      "Train on 307963 samples, validate on 54348 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.3564 - val_loss: 0.3640\n",
      "Epoch 2/8\n",
      "1s - loss: 0.3568 - val_loss: 0.3596\n",
      "Epoch 3/8\n",
      "1s - loss: 0.3572 - val_loss: 0.3547\n",
      "Epoch 4/8\n",
      "1s - loss: 0.3554 - val_loss: 0.3571\n",
      "Epoch 5/8\n",
      "1s - loss: 0.3562 - val_loss: 0.3594\n",
      "Epoch 6/8\n",
      "1s - loss: 0.3559 - val_loss: 0.3538\n",
      "Epoch 7/8\n",
      "1s - loss: 0.3543 - val_loss: 0.3540\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [01:58, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.3540 - val_loss: 0.3571\n",
      "batch size 346591\n",
      "small_class_sample_size 62276\n",
      "Oversampling small class to 17.9682% of the training data, 8 epochs\n",
      "Train on 294601 samples, validate on 51990 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.3333 - val_loss: 0.3313\n",
      "Epoch 2/8\n",
      "1s - loss: 0.3332 - val_loss: 0.3309\n",
      "Epoch 3/8\n",
      "1s - loss: 0.3340 - val_loss: 0.3290\n",
      "Epoch 4/8\n",
      "1s - loss: 0.3322 - val_loss: 0.3286\n",
      "Epoch 5/8\n",
      "1s - loss: 0.3310 - val_loss: 0.3292\n",
      "Epoch 6/8\n",
      "1s - loss: 0.3318 - val_loss: 0.3281\n",
      "Epoch 7/8\n",
      "1s - loss: 0.3317 - val_loss: 0.3287\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [02:08, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.3315 - val_loss: 0.3320\n",
      "batch size 332179\n",
      "small_class_sample_size 47864\n",
      "Oversampling small class to 14.4091% of the training data, 8 epochs\n",
      "Train on 282351 samples, validate on 49828 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.3055 - val_loss: 0.3027\n",
      "Epoch 2/8\n",
      "1s - loss: 0.3053 - val_loss: 0.3006\n",
      "Epoch 3/8\n",
      "1s - loss: 0.3040 - val_loss: 0.3008\n",
      "Epoch 4/8\n",
      "1s - loss: 0.3045 - val_loss: 0.2999\n",
      "Epoch 5/8\n",
      "1s - loss: 0.3033 - val_loss: 0.3000\n",
      "Epoch 6/8\n",
      "1s - loss: 0.3029 - val_loss: 0.2987\n",
      "Epoch 7/8\n",
      "1s - loss: 0.3022 - val_loss: 0.2982\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [02:17, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.3035 - val_loss: 0.2989\n",
      "batch size 318918\n",
      "small_class_sample_size 34603\n",
      "Oversampling small class to 10.8500% of the training data, 8 epochs\n",
      "Train on 271079 samples, validate on 47839 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.2716 - val_loss: 0.2708\n",
      "Epoch 2/8\n",
      "1s - loss: 0.2708 - val_loss: 0.2731\n",
      "Epoch 3/8\n",
      "1s - loss: 0.2705 - val_loss: 0.2694\n",
      "Epoch 4/8\n",
      "1s - loss: 0.2701 - val_loss: 0.2693\n",
      "Epoch 5/8\n",
      "1s - loss: 0.2709 - val_loss: 0.2711\n",
      "Epoch 6/8\n",
      "1s - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 7/8\n",
      "1s - loss: 0.2698 - val_loss: 0.2682\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [02:27, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.2698 - val_loss: 0.2688\n",
      "batch size 306674\n",
      "small_class_sample_size 22359\n",
      "Oversampling small class to 7.2909% of the training data, 8 epochs\n",
      "Train on 260672 samples, validate on 46002 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.2306 - val_loss: 0.2292\n",
      "Epoch 2/8\n",
      "1s - loss: 0.2301 - val_loss: 0.2288\n",
      "Epoch 3/8\n",
      "1s - loss: 0.2305 - val_loss: 0.2303\n",
      "Epoch 4/8\n",
      "1s - loss: 0.2306 - val_loss: 0.2285\n",
      "Epoch 5/8\n",
      "1s - loss: 0.2297 - val_loss: 0.2280\n",
      "Epoch 6/8\n",
      "1s - loss: 0.2281 - val_loss: 0.2306\n",
      "Epoch 7/8\n",
      "0s - loss: 0.2280 - val_loss: 0.2291\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [02:35,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.2282 - val_loss: 0.2269\n",
      "batch size 295336\n",
      "small_class_sample_size 11021\n",
      "Oversampling small class to 3.7318% of the training data, 8 epochs\n",
      "Train on 251034 samples, validate on 44302 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.1743 - val_loss: 0.1757\n",
      "Epoch 2/8\n",
      "1s - loss: 0.1741 - val_loss: 0.1754\n",
      "Epoch 3/8\n",
      "1s - loss: 0.1741 - val_loss: 0.1745\n",
      "Epoch 4/8\n",
      "1s - loss: 0.1740 - val_loss: 0.1743\n",
      "Epoch 5/8\n",
      "1s - loss: 0.1740 - val_loss: 0.1752\n",
      "Epoch 6/8\n",
      "1s - loss: 0.1737 - val_loss: 0.1756\n",
      "Epoch 7/8\n",
      "0s - loss: 0.1742 - val_loss: 0.1785\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [02:44,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.1742 - val_loss: 0.1745\n",
      "batch size 284807\n",
      "small_class_sample_size 492\n",
      "Oversampling small class to 0.1727% of the training data, 8 epochs\n",
      "Train on 242085 samples, validate on 42722 samples\n",
      "Epoch 1/8\n",
      "1s - loss: 0.0373 - val_loss: 0.0314\n",
      "Epoch 2/8\n",
      "0s - loss: 0.0326 - val_loss: 0.0304\n",
      "Epoch 3/8\n",
      "0s - loss: 0.0318 - val_loss: 0.0297\n",
      "Epoch 4/8\n",
      "1s - loss: 0.0312 - val_loss: 0.0294\n",
      "Epoch 5/8\n",
      "0s - loss: 0.0309 - val_loss: 0.0291\n",
      "Epoch 6/8\n",
      "0s - loss: 0.0307 - val_loss: 0.0289\n",
      "Epoch 7/8\n",
      "1s - loss: 0.0305 - val_loss: 0.0287\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [02:52,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 0.0303 - val_loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9973\n",
      "Counter({0: 284471, 1: 336})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[284007,    308],\n",
       "       [   464,     28]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X           = df.drop(['Class'], axis = 1).as_matrix()\n",
    "y           = df['Class'].as_matrix()\n",
    "predictions = model.predict_classes(X, batch_size = 2048, verbose = 0)\n",
    "good_preds  = (predictions == y).sum()\n",
    "total_preds = X.shape[0]\n",
    "print('accuracy: %.4f' % (good_preds / total_preds))\n",
    "print(Counter(predictions))\n",
    "confusion_matrix(y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
