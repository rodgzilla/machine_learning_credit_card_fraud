{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path    = '../data/'\n",
    "random_state = 142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>0.083386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>-0.153350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>-0.050468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>0.691625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068  0.193679   \n",
       "1  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820 -0.063700   \n",
       "2 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454  0.639776   \n",
       "3 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150  0.192071   \n",
       "4 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999  0.479302   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.082637  0.331128  0.083386  ...   -0.024923  0.382854 -0.176911   \n",
       "1  0.071253 -0.232494 -0.153350  ...   -0.307377 -0.880077  0.162201   \n",
       "2  0.207373 -1.378675  0.190700  ...    0.337632  1.063358  1.456320   \n",
       "3  0.316018 -1.262503 -0.050468  ...   -0.147443  0.007267 -0.304777   \n",
       "4 -0.226510  0.744326  0.691625  ...   -0.012839  1.100011 -0.220123   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  Class  \n",
       "0  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964      0  \n",
       "1 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475      0  \n",
       "2 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686      0  \n",
       "3 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534      0  \n",
       "4  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(data_path + 'standardized_credit_card.csv')\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_filter = original_df.Class == 1\n",
    "fraud        = original_df[ fraud_filter]\n",
    "non_fraud    = original_df[~fraud_filter]\n",
    "n_fraud      = fraud.shape[0]\n",
    "fraud_subset = fraud.sample(n_fraud // 2, random_state = random_state)\n",
    "df           = pd.concat([non_fraud, fraud_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(df, non_anom_proportion):\n",
    "    X                  = df.drop(['Class'], axis = 1)\n",
    "    y                  = df['Class']\n",
    "    fraud              = X[y == 1]\n",
    "    non_fraud          = X[y == 0]\n",
    "    fraud_number       = fraud.shape[0]\n",
    "    undersampling_size = int(round(fraud_number * non_anom_proportion))\n",
    "    small_X            = pd.concat([fraud, non_fraud.sample(undersampling_size, random_state = random_state)])\n",
    "    small_y            = np.array([1] * fraud_number + [0] * undersampling_size)\n",
    "    \n",
    "    return small_X, small_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_various_undersampling(df, start_value, end_value, steps, create_model, test_size = 0.15):\n",
    "    train_confusion_matrices  = []\n",
    "    test_confusion_matrices   = []\n",
    "    full_confusion_matrices   = []\n",
    "    undersampling_proportions = np.linspace(start_value, end_value, steps)\n",
    "    X_full = df.drop(['Class'], axis = 1)\n",
    "    y_full = df['Class']\n",
    "    \n",
    "    for prop in undersampling_proportions:\n",
    "        X, y                             = generate_dataset(df, prop)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = random_state)\n",
    "        model                            = create_model()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_confusion_matrices.append(confusion_matrix(y_train, model.predict(X_train)))\n",
    "        test_confusion_matrices.append(confusion_matrix(y_test, model.predict(X_test)))\n",
    "        full_confusion_matrices.append(confusion_matrix(y_full, model.predict(X_full)))\n",
    "        \n",
    "    return undersampling_proportions, train_confusion_matrices, test_confusion_matrices, full_confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_model                                                 = lambda : RandomForestClassifier(n_estimators = 20, n_jobs = -1)\n",
    "proportions, train_conf_mats, test_conf_mats, full_conf_mats = try_various_undersampling(df, 1, 100, 25, create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 1.00x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[416   0]\n",
      " [  0 420]]\n",
      "Test set confusion matrix\n",
      "[[76  0]\n",
      " [14 58]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[278065   6250]\n",
      " [    14    478]]\n",
      "##################################################\n",
      "\n",
      "########## 5.12x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[2129    0]\n",
      " [   1  431]]\n",
      "Test set confusion matrix\n",
      "[[393   0]\n",
      " [  6  54]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[283587    728]\n",
      " [     7    485]]\n",
      "##################################################\n",
      "\n",
      "########## 9.25x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[3864    0]\n",
      " [   4  418]]\n",
      "Test set confusion matrix\n",
      "[[686   1]\n",
      " [  9  61]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[283993    322]\n",
      " [    13    479]]\n",
      "##################################################\n",
      "\n",
      "########## 13.38x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[5580    0]\n",
      " [   6  425]]\n",
      "Test set confusion matrix\n",
      "[[998   2]\n",
      " [  5  56]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284031    284]\n",
      " [    11    481]]\n",
      "##################################################\n",
      "\n",
      "########## 17.50x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[7307    0]\n",
      " [   8  421]]\n",
      "Test set confusion matrix\n",
      "[[1302    1]\n",
      " [   5   58]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284102    213]\n",
      " [    13    479]]\n",
      "##################################################\n",
      "\n",
      "########## 21.62x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[9032    0]\n",
      " [   7  423]]\n",
      "Test set confusion matrix\n",
      "[[1607    1]\n",
      " [   8   54]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284093    222]\n",
      " [    15    477]]\n",
      "##################################################\n",
      "\n",
      "########## 25.75x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[10761     0]\n",
      " [    4   421]]\n",
      "Test set confusion matrix\n",
      "[[1908    0]\n",
      " [   6   61]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284144    171]\n",
      " [    10    482]]\n",
      "##################################################\n",
      "\n",
      "########## 29.88x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[12488     0]\n",
      " [    6   417]]\n",
      "Test set confusion matrix\n",
      "[[2210    0]\n",
      " [   7   62]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284164    151]\n",
      " [    13    479]]\n",
      "##################################################\n",
      "\n",
      "########## 34.00x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[14210     0]\n",
      " [    6   421]]\n",
      "Test set confusion matrix\n",
      "[[2518    0]\n",
      " [  10   55]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284180    135]\n",
      " [    16    476]]\n",
      "##################################################\n",
      "\n",
      "########## 38.12x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[15936     0]\n",
      " [    7   419]]\n",
      "Test set confusion matrix\n",
      "[[2820    2]\n",
      " [  10   56]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284132    183]\n",
      " [    17    475]]\n",
      "##################################################\n",
      "\n",
      "########## 42.25x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[17664     0]\n",
      " [   12   411]]\n",
      "Test set confusion matrix\n",
      "[[3123    0]\n",
      " [  10   59]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284160    155]\n",
      " [    22    470]]\n",
      "##################################################\n",
      "\n",
      "########## 46.38x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[19388     0]\n",
      " [    9   414]]\n",
      "Test set confusion matrix\n",
      "[[3426    2]\n",
      " [  10   59]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284181    134]\n",
      " [    19    473]]\n",
      "##################################################\n",
      "\n",
      "########## 50.50x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[21115     0]\n",
      " [   13   409]]\n",
      "Test set confusion matrix\n",
      "[[3731    0]\n",
      " [  14   56]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284180    135]\n",
      " [    27    465]]\n",
      "##################################################\n",
      "\n",
      "########## 54.62x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[22841     0]\n",
      " [   10   411]]\n",
      "Test set confusion matrix\n",
      "[[4035    0]\n",
      " [  14   57]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284187    128]\n",
      " [    24    468]]\n",
      "##################################################\n",
      "\n",
      "########## 58.75x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[24561     0]\n",
      " [    9   417]]\n",
      "Test set confusion matrix\n",
      "[[4343    1]\n",
      " [  11   55]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284200    115]\n",
      " [    20    472]]\n",
      "##################################################\n",
      "\n",
      "########## 62.88x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[26277     0]\n",
      " [    9   426]]\n",
      "Test set confusion matrix\n",
      "[[4656    1]\n",
      " [   7   50]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284190    125]\n",
      " [    16    476]]\n",
      "##################################################\n",
      "\n",
      "########## 67.00x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[28013     0]\n",
      " [    9   415]]\n",
      "Test set confusion matrix\n",
      "[[4948    3]\n",
      " [   9   59]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284211    104]\n",
      " [    18    474]]\n",
      "##################################################\n",
      "\n",
      "########## 71.12x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[29748     1]\n",
      " [   11   403]]\n",
      "Test set confusion matrix\n",
      "[[5242    3]\n",
      " [  10   68]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284214    101]\n",
      " [    21    471]]\n",
      "##################################################\n",
      "\n",
      "########## 75.25x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[31472     0]\n",
      " [    6   409]]\n",
      "Test set confusion matrix\n",
      "[[5551    0]\n",
      " [  11   66]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284227     88]\n",
      " [    17    475]]\n",
      "##################################################\n",
      "\n",
      "########## 79.38x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[33192     1]\n",
      " [    7   412]]\n",
      "Test set confusion matrix\n",
      "[[5858    1]\n",
      " [   6   67]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284225     90]\n",
      " [    13    479]]\n",
      "##################################################\n",
      "\n",
      "########## 83.50x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[34920     0]\n",
      " [   11   406]]\n",
      "Test set confusion matrix\n",
      "[[6162    0]\n",
      " [  13   62]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284246     69]\n",
      " [    24    468]]\n",
      "##################################################\n",
      "\n",
      "########## 87.62x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[36652     0]\n",
      " [    6   405]]\n",
      "Test set confusion matrix\n",
      "[[6459    1]\n",
      " [  15   66]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284240     75]\n",
      " [    21    471]]\n",
      "##################################################\n",
      "\n",
      "########## 91.75x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[38378     0]\n",
      " [    8   402]]\n",
      "Test set confusion matrix\n",
      "[[6762    1]\n",
      " [  13   69]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284238     77]\n",
      " [    21    471]]\n",
      "##################################################\n",
      "\n",
      "########## 95.88x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[40094     0]\n",
      " [   12   406]]\n",
      "Test set confusion matrix\n",
      "[[7076    0]\n",
      " [  10   64]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284240     75]\n",
      " [    22    470]]\n",
      "##################################################\n",
      "\n",
      "########## 100.00x more of non fraud ###############\n",
      "Training set confusion matrix\n",
      "[[41816     0]\n",
      " [    5   417]]\n",
      "Test set confusion matrix\n",
      "[[7383    1]\n",
      " [  10   60]]\n",
      "Full imbalanced dataset confusion matrix\n",
      "[[284234     81]\n",
      " [    15    477]]\n",
      "##################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, prop in enumerate(proportions):\n",
    "    print('########## %.2fx more of non fraud ###############' % prop)\n",
    "    print('Training set confusion matrix')\n",
    "    print(train_conf_mats[i])\n",
    "    print('Test set confusion matrix')\n",
    "    print(test_conf_mats[i])\n",
    "    print('Full imbalanced dataset confusion matrix')\n",
    "    print(full_conf_mats[i])\n",
    "    print('##################################################\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
